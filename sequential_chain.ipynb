{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "594de96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import operating system\n",
    "## load dotenv forn api key \n",
    "## import helpful init model from langchain chain model help to load llm\n",
    "## import prompt template to determine how i write my template of query\n",
    "## import llm chain to combine more than two query\n",
    "## import sequential chain to combine query related to each other like output of first will be the input of second\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain.chat_models import init_chat_model\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import  LLMChain ,SequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f927dae5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()           ## load dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45e507b9",
   "metadata": {},
   "source": [
    "## chat model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45dbd484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am doing well, thank you for asking! As a large language model, I don't experience emotions or feelings in the same way humans do, but I am functioning optimally and ready to assist you with your requests. How can I help you today?\n"
     ]
    }
   ],
   "source": [
    "## chat model  =  init helps to use llm having inputs are  model name, provider, temp\n",
    "# response = firstly invoke chat model i give input to chat model \n",
    "# print content means the response of chat model of my query \n",
    "\n",
    "\n",
    "chat_model = init_chat_model(model = \"gemini-2.0-flash\",\n",
    "                             model_provider=\"google-genai\",\n",
    "                             temperature =0.3)\n",
    "response = chat_model.invoke(\"how are you\")\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "619e0e5c",
   "metadata": {},
   "source": [
    "## template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d624396e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what is the capital of germany\n"
     ]
    }
   ],
   "source": [
    "## determine template from prompt template, means the way of my query\n",
    "# in input it include template where we add a specific thing from which i want to know here it is {topic}\n",
    "\n",
    "template = PromptTemplate(input_variables = [\"topic\"],\n",
    "                          template = \"what is the capital of {topic}\")\n",
    "prompt = template.format(topic = \"germany\")\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879043c0",
   "metadata": {},
   "source": [
    "## sequential chain\n",
    "\n",
    " in sequential i want to combine query in sequence means the output of first will be the input of second and moving in this manner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e709fcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what is the capital of DELHI\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_15412\\3359812028.py:6: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  capital_chain = LLMChain(llm = chat_model,prompt = capital_template,output_key = \"capital\")\n"
     ]
    }
   ],
   "source": [
    "## firstly i create a template for capital and provide input \n",
    "## then i created chain  providing llm which is chat model ,prompt is capital prompt i gave it earlier, its output is capital because\n",
    "## i want to ask what is the capital of {place} \n",
    "## place can be anything\n",
    "\n",
    "\n",
    "capital_template = PromptTemplate(input_variables = [\"PLACE\"],\n",
    "                                template = \"what is the capital of {PLACE}\")\n",
    "prompt = template.format(topic = \"DELHI\") \n",
    "print(prompt)\n",
    "\n",
    "capital_chain = LLMChain(llm = chat_model,prompt = capital_template,output_key = \"capital\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e139ca4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## doing same for food chain but here input is capital and output is food\n",
    "\n",
    "food_template = PromptTemplate(input_variables = [\"capital\"],\n",
    "                               template = \"what is the delicious food of {capital}\")\n",
    "prompt = template.format(topic = \"capital\")\n",
    "\n",
    "food_chain = LLMChain(llm= chat_model,prompt = food_template,output_key = \"food\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ad5cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## same this time also food is input and colour is output\n",
    "\n",
    "colour_template = PromptTemplate(input_variables = [\"food\"],\n",
    "                                 template = \"what is the colour of delicious {food}\")\n",
    "\n",
    "colour_chain = LLMChain(llm = chat_model,prompt = colour_template,output_key = \"colour\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646bfa9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\AppData\\Local\\Temp\\ipykernel_15412\\2071312020.py:6: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  ans = overall_chain({\"PLACE\":\"India\"})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{'PLACE': 'India', 'capital': 'The capital of India is **New Delhi**.', 'food': 'New Delhi, being the capital of India, is a melting pot of cultures and cuisines. It doesn\\'t have one single dish that defines it, but rather a wide array of delicious foods that are popular and representative of the city. Here are some of the most iconic and delicious foods you can find in New Delhi:\\n\\n*   **Butter Chicken:** A creamy and rich tomato-based curry with tandoori chicken, it\\'s a Delhi staple.\\n*   **Chhole Bhature:** Spicy chickpeas (chhole) served with fried bread (bhature) is a hearty and flavorful breakfast or brunch option.\\n*   **Biryani:** While originating elsewhere, Delhi has its own delicious versions of biryani, often featuring fragrant rice, tender meat, and aromatic spices.\\n*   **Kebabs:** From succulent seekh kebabs to melt-in-your-mouth galouti kebabs, Delhi is a kebab lover\\'s paradise.\\n*   **Parathe:** Stuffed flatbreads cooked on a griddle, parathe come in countless variations, from potato (aloo) to cauliflower (gobi) to paneer (cheese).\\n*   **Momos:** Steamed or fried dumplings filled with vegetables or meat, momos are a popular street food snack.\\n*   **Street Food:** Delhi\\'s street food scene is legendary, with options like gol gappe (pani puri), aloo tikki, chaat, and more.\\n*   **Daal Makhani:** A slow-cooked creamy lentil dish, often served with rice or naan.\\n*   **Nihari:** A slow-cooked meat stew, traditionally eaten for breakfast.\\n\\nSo, while there isn\\'t one single \"delicious food\" of New Delhi, the city offers a diverse and vibrant culinary landscape with many delicious options to explore.', 'colour': 'Based on the description of the iconic foods of New Delhi, the \"colour\" of delicious New Delhi would be a vibrant and complex mix, reflecting the diverse cuisine:\\n\\n*   **Orange-Red:** From the Butter Chicken, Biryani, and the spices used in many dishes.\\n*   **Golden-Brown:** From the fried Bhature, Kebabs, and Parathe.\\n*   **Green:** From the coriander and other herbs used as garnishes and in fillings.\\n*   **Creamy White:** From the Daal Makhani and the creamy sauces used in some dishes.\\n*   **Various other colours:** Depending on the specific street food or dish, you might find yellows, browns, and other hues.\\n\\nEssentially, the colour of delicious New Delhi is a **multicolored, warm, and inviting palette**, reflecting the richness and variety of its food scene.'}\n"
     ]
    }
   ],
   "source": [
    "## here i combine the three chains  and print result \n",
    "\n",
    "\n",
    "overall_chain = SequentialChain(chains = [capital_chain,food_chain,colour_chain],\n",
    "                                input_variables = [\"PLACE\"],\n",
    "                                output_variables = [\"capital\",\"food\",\"colour\"],\n",
    "                                verbose = True)\n",
    "\n",
    "ans = overall_chain({\"PLACE\":\"India\"})\n",
    "print(ans)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
